<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <link href="style.css" rel="stylesheet">
    <title>Moonshine Vision Lab.</title>
  </head>
  <body>
    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
      <symbol id="mvl-logo" viewBox="0 0 64 64">
        <path style="fill: #fff; fill-rule: evenodd;" d="M51.911,50.133h0c0,3.338-8.914,6.044-19.911,6.044s-19.911-2.706-19.911-6.044h0V33.422h0c0-8.005,6.171-14.749,14.578-16.789V9.956a2.133,2.133,0,1,1,0-4.267H37.333a2.133,2.133,0,1,1,0,4.267v6.678c8.407,2.04,14.578,8.784,14.578,16.789h0V50.133h0Z"/>
        <path style="fill: #000; fill-rule: evenodd;" d="M53.333,50.489c0,3.927-9.551,7.111-21.333,7.111s-21.333-3.184-21.333-7.111h0V33.422c0-8.322,6.107-15.383,14.578-17.879V11.081a3.556,3.556,0,0,1,1.422-6.814H37.333a3.556,3.556,0,0,1,3.484,4.267h0.072a4.622,4.622,0,0,1,4.622,4.622,6.376,6.376,0,0,1-1.842,4.49c5.819,3.365,9.664,9.174,9.664,15.776V50.489h0ZM42.667,13.156a1.778,1.778,0,0,0-1.778-1.778H38.756v4.165q1.1,0.324,2.139.748A3.412,3.412,0,0,0,42.667,13.3V13.156Zm-6.756,4.627V8.533h1.422a0.711,0.711,0,0,0,0-1.422H26.667a0.711,0.711,0,0,0,0,1.422h1.422v9.249c-7.916,1.476-13.948,7.337-14.531,14.5a19.072,19.072,0,0,0,7.471,2.925,10.953,10.953,0,0,1,1-3.637l0.033,0.035,0.3,0.3a3.7,3.7,0,0,0,5.229,0l0.05-.05a3.7,3.7,0,0,0,0-5.229l-0.3-.3L27.3,26.293a11.026,11.026,0,0,1,15.667,8.915,19.078,19.078,0,0,0,7.471-2.925C49.86,25.119,43.828,19.258,35.911,17.782ZM50.489,34.247c-2.937,2.226-10.108,3.8-18.489,3.8s-15.552-1.572-18.489-3.8V49.778c0,2.749,8.278,4.978,18.489,4.978s18.489-2.229,18.489-4.978V34.247Z"/>
        <path style="fill: #000; fill-rule: evenodd;" d="M19.9,49.81V48.6q-0.592-.255-1.181-0.525V45.924L18.6,41.6l0.041,0q1.523,4.3,3.066,8.492,0.766,0.165,1.535.3,1.515-3.621,3.041-7.337l0.042,0.012-0.035,4.558v1.938q-0.572.037-1.142,0.061v1.215q2.11,0.3,4.235.411V50.044q-0.549-.133-1.1-0.279V42.507q0.549-.062,1.1-0.137V41.148q-2.071-.111-4.13-0.4-1.344,3.337-2.679,6.6l-0.042-.008q-1.379-3.8-2.746-7.672-1.486-.383-2.953-0.86-0.526-.171-1.049-0.355v1.222q0.523,0.288,1.049.563V47.5q-0.526-.067-1.049-0.146v1.215Q17.821,49.281,19.9,49.81Zm16.318,1.337q1.543-4.522,3.078-9.142,0.461-.125.922-0.259V40.524q-1.925.328-3.866,0.5v1.222q0.538,0.022,1.075.031-1,3.1-2.01,6.161l-0.148.552-0.042,0-0.155-.545q-1.007-2.919-2.015-5.88,0.462-.079.923-0.167V41.178q-2.04.082-4.081-.005v1.222q0.458,0.075.916,0.142,1.649,4.429,3.3,8.747Q35.165,51.238,36.217,51.147Zm12.044-2.6V45.516q-0.752.265-1.511,0.5l-0.1,1.509q-1.4.439-2.815,0.791V41.2q0.606-.255,1.21-0.526V39.447q-0.6.167-1.21,0.318-1.006.251-2.02,0.458-0.538.11-1.078,0.208v1.222q0.54,0.006,1.078,0v7.257q-0.538.214-1.078,0.416v1.215A48.972,48.972,0,0,0,48.261,48.551Z"/>
      </symbol>
    </svg>
    <div class="container">
      <header class="row align-items-end py-2 mb-3 border-bottom border-3">
        <div class="col-12 col-lg-4 py-1">
          <a href="index.html" class="d-flex align-items-center justify-content-center justify-content-lg-start text-dark text-decoration-none">
            <svg class="flex-shrink-0" width="4rem" height="4rem"><use xlink:href="#mvl-logo"/></svg>
            <div class="fw-light lh-sm">
              <div class="fs-4">Moonshine Vision Lab</div>
              <div class="fs-6">Sungshin Women's University</div>
            </div>
          </a>
        </div><!-- /.col(logo) -->
        <div class="col-12 col-lg-8 py-1">
          <ul class="nav nav-pills justify-content-center justify-content-lg-end">
            <li class="nav-item"><a href="index.html" class="nav-link">Home</a></li>
            <li class="nav-item"><a href="people.html" class="nav-link">People</a></li>
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle active bg-secondary" data-bs-toggle="dropdown" href="#" role="button" aria-expanded="false">Research</a>
              <ul class="dropdown-menu" style="z-index: 9999!important;">
                <li><a class="dropdown-item" href="publications.html" aria-current="page">Publications</a></li>
                <li><a class="dropdown-item" href="posters-talks.html">Posters & Talks</a></li>
                <li><hr class="dropdown-divider"></li>
                <li><a class="dropdown-item active" href="research-mvl.html">Research @ MVL</a></li>
              </ul>
            </li>
            <li class="nav-item"><a href="contact.html" class="nav-link">Contact</a></li>
          </ul>
        </div><!-- /.col(nav) -->
      </header>

      <main class="row pb-4">
        <div class="col-md-8 col-lg-9">
          <h3 id="ensemble-processing">Ensemble Processing</h3>
          <p>
            Imagine a speaker looking at her audience, trying to get a sense of how many of them are bored.
            Certainly, people can estimate ensemble properties from a group of objects (e.g., average emotion from a crowd of faces, color diversity from an array of colored letters).
            These judgments, although they may seem trivial, require an ability to process visual objects within a brief moment insufficient for processing each object one by one.
            In MVL, we study whether and how ensemble judgments are different from judgments about individual objects.
            Our research topics include, but are not limited to, the following:
          </p>
          <p>
            <span class="inline-heading">Masked-face perception and masked-crowd perception.</span>
            During the COVID-19 pandemic, people learned to recognize others' faces with a mask covering about half of the face.
            We study whether people learned i) a way to deal with visual information loss due to face coverings or ii) a new category of objects, i.e., masked face (imagine a dog expert learning to recognize wolves).
            We also test whether this learning transfers to ensemble judgments about a crowd of masked faces.
          </p>
          <p>
            <span class="inline-heading">Perception of identities and facial expressions in a crowd.</span>
            People's abilities to identify an individual and recognize other's facial expression are correlated to some extent (e.g., <a href="https://doi.org/10.1080/02699931.2018.1535425" target="_blank">Connolly et al. 2019</a>).
            We question whether this correlation holds when people make ensemble judgments about identities and facial expressions from a crowd of faces.
          </p>
          <p>
            <span class="inline-heading">Cost-free ensemble processing.</span>
            <a href="https://doi.org/10.1177/0956797614532656" target="_blank">Bronfman et al. (2014)</a> found that people could judge the color diversity of unattented letters in a 6-by-4 grid while attending to a cued row relevant to the primary task, and interpreted this finding as evidence of cost-free ensemble processing.
            We test an alternative explanation that attentional window for the primary task may encompass some letters adjacent to the cued row, which could contribute to color diversity judgments.
          </p>
          <p>
            <span class="inline-heading">Multitasking and ensemble processing.</span>
            In everyday multitasking situations, people perform a secondary task (e.g., peeking at smartphone notifications during a class) easily with a fraction of attentional resources.
            In ensemble processing experiments, people can estimate ensemble properties from a group of objects, but with a fraction of attentional resources given to individual objects.
            We ask whether these two types of processing rely on shared mechanisms.
          </p>

          <h3 id="perceptual-rhythms">Perceptual Rhythms and Binocular Rivlary</h3>
          <p>
            <cite>
              &ldquo;Perceptual experience seems to unfold seamlessly, but this belies the evidence that perception comprises discrete epochs in which perceptual responsiveness varies periodically over time.
              The notion of discrete, oscillatory fluctuations in perceptual responsiveness also emerges from studies showing neuronal response modulations in brain activity measured using electroencephalography (EEG) that match fluctuations in perceptual responsiveness.
              <br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;It is easy to imagine how oscillatory fluctuations in endogenous neural activity could interact with appropriately aligned pulses of neural activity evoked by discrete sensory stimulation.
              But recent results suggest that discrete sensory stimulation is not a prerequisite for producing neural signatures of oscillatory fluctuations. Even during prolonged, unchanging visual stimulation, indirect evidence for an influence of endogenous brain rhythms emerges.
              Thus, for example, neural activity measured during perception of bistable stimuli carries subtle but reliable signatures of periodicity in the EEG activity associated with visual stimuli provoking bistability.
              These EEG results reveal the influence of endogenous, oscillatory neural modulation embedded within prolonged, exogenously generated sensory neural signals that culminate in competing perceptual interpretations.
              <br>
              &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Is it feasible to see telltale signs of periodicity within the records of fluctuating bistable perception itself, not just in the concomitant EEG signals?
              While simple in principle, the practical challenge involves extracting a signature of oscillations in perceptual dominance within time series that are characteristically stochastic.
              In principle this should be possible, just as it is feasible to uncover weak stimulus-evoked activity from EEG recordings given a sufficient number of discrete instances of signal within noise.&rdquo;
            </cite>
            &mdash; <a href="https://doi.org/10.1073/pnas.1905174116" target="_blank">Cha & Blake (2019)</a>
          </p>
        </div><!-- /.col-8(research topic) -->

        <div class="col-md-4 col-lg-3">
          <h4>Collaborators</h4>
          <div class="list-group list-group-flush">
            <a href="http://gauthier.psy.vanderbilt.edu/" target="_blank" class="list-group-item list-group-item-action">Isabel Gauthier</a>
            <a href="https://sites.google.com/view/vcnlskku/" target="_blank" class="list-group-item list-group-item-action">Min-Suk Kang</a>
            <a href="http://www.psy.vanderbilt.edu/faculty/blake/" target="_blank" class="list-group-item list-group-item-action">Randolph Blake</a>
            <a href="http://vcc.yonsei.ac.kr/" target="_blank" class="list-group-item list-group-item-action">Sang Chul Chong</a>
          </div>
        </div><!-- /.col(collaborators) -->
      </main>
    </div><!-- /.container -->

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>
  </body>
</html>